# Task 04: Stage 4 - Knowledge Extractor

**Status**: [ ] TODO
**Estimated Time**: 6 hours
**Dependencies**: Task 03 (Cleaner)
**Priority**: CRITICAL
**File**: `lib/knowledge-extractor.js`

---

## ğŸ“‹ Description

**MOST IMPORTANT STAGE**: Transform cleaned paragraphs into structured knowledge objects with semantic meaning. This extracts topics, entities, key concepts, quotes, and creates meaningful knowledge chunks for the chatbot.

---

## ğŸ¯ Goals

1. Segment paragraphs by topics
2. Extract named entities (people, places, concepts)
3. Identify and extract key quotes
4. Extract facts, insights, and principles
5. Classify knowledge type (advice, principle, story, etc.)
6. Assign importance levels
7. Optional: Auto-generate Q&A pairs

---

## âœ… Acceptance Criteria

- [ ] Identifies distinct topics in transcript
- [ ] Extracts entities: people, concepts, ages, references
- [ ] Preserves important quotes verbatim
- [ ] Creates structured knowledge objects
- [ ] Assigns appropriate categories
- [ ] Links related knowledge objects
- [ ] Maintains timestamp traceability
- [ ] Extracts 30-50 knowledge objects from transcript

---

## ğŸ”§ Implementation

### lib/knowledge-extractor.js

```javascript
const { OpenAI } = require('openai')

// Initialize OpenAI (optional - for advanced extraction)
const openai = process.env.OPENAI_API_KEY ? new OpenAI() : null

/**
 * Extract topics using basic NLP
 */
function extractTopics(paragraphs) {
  // Keywords that indicate topic shifts
  const topicIndicators = [
    'é»„é‡‘ç‡', 'ä¾¡å€¤è¦³', 'äººé–“é–¢ä¿‚', 'ä¿¡ç”¨', 'èª å®Ÿ',
    'å¤‰ãˆã‚‹', 'è·é›¢', 'æ™‚é–“', 'ç´„æŸ', 'ãŠé‡‘'
  ]

  const topics = []
  let currentTopic = {
    name: '',
    paragraphs: [],
    keywords: []
  }

  paragraphs.forEach((para, idx) => {
    // Simple keyword-based topic detection
    const foundKeywords = topicIndicators.filter(keyword =>
      para.fullText.includes(keyword)
    )

    if (foundKeywords.length > 0) {
      if (currentTopic.paragraphs.length > 0) {
        topics.push({ ...currentTopic })
      }

      currentTopic = {
        name: foundKeywords[0],
        paragraphs: [para],
        keywords: foundKeywords
      }
    } else {
      currentTopic.paragraphs.push(para)
    }
  })

  if (currentTopic.paragraphs.length > 0) {
    topics.push(currentTopic)
  }

  return topics
}

/**
 * Extract named entities from text
 */
function extractEntities(text) {
  const entities = {
    people: [],
    concepts: [],
    organizations: [],
    ages: [],
    numbers: []
  }

  // People patterns
  const peoplePatterns = [
    /é’æœ¨[ã•ã‚“]?/g,
    /é‡ä¸­[éƒæ¬¡éƒ]?[å…ˆç”Ÿ]?/g,
    /ç«¹æ²¢[ã•ã‚“]?/g,
    /æ¾ä¸‹[ä¹‹åŠ©]?/g
  ]

  peoplePatterns.forEach(pattern => {
    const matches = text.match(pattern)
    if (matches) {
      entities.people.push(...matches.filter(m => !entities.people.includes(m)))
    }
  })

  // Concepts
  const conceptPatterns = [
    'é»„é‡‘ç‡', 'ãƒã‚¤ãƒ–ãƒ«', 'ãƒã‚¿ã‚¤', 'ä¾¡å€¤è¦³', 'ä¿¡ç”¨',
    'èª å®Ÿ', 'ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒ¯ãƒ¼ãƒ«ãƒ‰', 'å¸¸æ™‚ä¸–ç•Œ'
  ]

  conceptPatterns.forEach(concept => {
    if (text.includes(concept)) {
      entities.concepts.push(concept)
    }
  })

  // Organizations
  const orgPatterns = ['ã‚¢ãƒãƒ¥ãƒ¼ãƒ¡ãƒ³ãƒˆ', 'æ±äº¬ä¼šé¤¨', 'ä¸€æ©‹å¤§å­¦']
  orgPatterns.forEach(org => {
    if (text.includes(org)) {
      entities.organizations.push(org)
    }
  })

  // Ages
  const ageMatches = text.match(/(\d{1,2})æ­³/g)
  if (ageMatches) {
    entities.ages = ageMatches.map(m => parseInt(m))
  }

  // Numbers (money, counts)
  const numberMatches = text.match(/(\d+)ä¸‡/g)
  if (numberMatches) {
    entities.numbers = numberMatches
  }

  return entities
}

/**
 * Extract important quotes (sentences with ã€Œã€or specific patterns)
 */
function extractQuotes(text) {
  const quotes = []

  // Quoted text
  const quotedMatches = text.match(/ã€Œ([^ã€]+)ã€/g)
  if (quotedMatches) {
    quotes.push(...quotedMatches.map(q => q.replace(/[ã€Œã€]/g, '')))
  }

  // Important statements (ending with ã§ã™/ã¾ã™/ã /ã‚ˆ etc)
  const importantPatterns = [
    /([^ã€‚]+ã“ã¨ãŒå¤§åˆ‡[^ã€‚]*ã€‚)/g,
    /([^ã€‚]+ã—ã¦ã¯ã„ã‘ãªã„[^ã€‚]*ã€‚)/g,
    /([^ã€‚]+ã¹ã[^ã€‚]*ã€‚)/g,
    /([^ã€‚]+ãªã‚“ã§ã™ã€‚)/g
  ]

  importantPatterns.forEach(pattern => {
    const matches = text.match(pattern)
    if (matches) {
      quotes.push(...matches)
    }
  })

  return [...new Set(quotes)] // Remove duplicates
}

/**
 * Determine knowledge type
 */
function classifyKnowledgeType(text) {
  if (text.includes('ã¹ã') || text.includes('ã—ãŸæ–¹ãŒã„ã„')) {
    return 'advice'
  }
  if (text.includes('åŸå‰‡') || text.includes('å¤§åˆ‡') || text.includes('é‡è¦')) {
    return 'principle'
  }
  if (text.includes('æ­³') || text.includes('æ™‚') || text.includes('çµŒé¨“')) {
    return 'biographical_event'
  }
  if (text.includes('ä¾‹ãˆã°') || text.includes('ã‚ã‚‹æ™‚')) {
    return 'anecdote'
  }

  return 'general'
}

/**
 * Determine importance level
 */
function assessImportance(knowledgeObject) {
  let score = 0

  // Has quotes
  if (knowledgeObject.content.quotes && knowledgeObject.content.quotes.length > 0) {
    score += 2
  }

  // Named entities
  if (knowledgeObject.entities.people.length > 0) {
    score += 1
  }

  // Key concepts
  const keyConcepts = ['é»„é‡‘ç‡', 'ä¾¡å€¤è¦³', 'ä¿¡ç”¨', 'äººç”Ÿ']
  if (knowledgeObject.entities.concepts.some(c => keyConcepts.includes(c))) {
    score += 2
  }

  // Length (longer = more detailed)
  if (knowledgeObject.content.main.length > 100) {
    score += 1
  }

  if (score >= 4) return 'high'
  if (score >= 2) return 'medium'
  return 'low'
}

/**
 * Main extraction function
 */
async function extractKnowledge(paragraphs, options = {}) {
  const {
    useAI = false, // Use OpenAI for advanced extraction
    generateQA = false
  } = options

  const knowledgeObjects = []
  let knowledgeId = 1

  // Group by topics first
  const topics = extractTopics(paragraphs)

  for (const topic of topics) {
    // Combine topic paragraphs
    const topicText = topic.paragraphs.map(p => p.fullText).join(' ')

    // Extract components
    const entities = extractEntities(topicText)
    const quotes = extractQuotes(topicText)
    const type = classifyKnowledgeType(topicText)

    // Create knowledge object
    const knowledge = {
      knowledgeId: `k${String(knowledgeId).padStart(3, '0')}`,
      topic: topic.name || 'General',
      type,
      content: {
        main: topicText.substring(0, 200) + '...', // Summary
        context: topicText,
        quotes: quotes.slice(0, 3), // Top 3 quotes
        keyTakeaway: quotes[0] || topicText.substring(0, 100)
      },
      entities,
      timestamp: {
        start: topic.paragraphs[0].startTime,
        end: topic.paragraphs[topic.paragraphs.length - 1].endTime
      },
      metadata: {
        importance: 'medium', // Will be assessed
        category: 'life_philosophy',
        sentiment: 'neutral',
        themes: topic.keywords,
        segmentIds: topic.paragraphs.flatMap(p => p.segmentIds)
      }
    }

    // Assess importance
    knowledge.metadata.importance = assessImportance(knowledge)

    knowledgeObjects.push(knowledge)
    knowledgeId++
  }

  // Optional: Use AI for better extraction
  if (useAI && openai) {
    // Enhance with OpenAI (implementation optional)
    console.log('AI enhancement enabled - would use OpenAI API here')
  }

  return {
    knowledge: knowledgeObjects,
    stats: {
      totalKnowledgeObjects: knowledgeObjects.length,
      highImportance: knowledgeObjects.filter(k => k.metadata.importance === 'high').length,
      mediumImportance: knowledgeObjects.filter(k => k.metadata.importance === 'medium').length,
      lowImportance: knowledgeObjects.filter(k => k.metadata.importance === 'low').length,
      topics: topics.length
    }
  }
}

module.exports = {
  extractKnowledge,
  extractEntities,
  extractQuotes,
  extractTopics,
  classifyKnowledgeType,
  assessImportance
}
```

---

## ğŸ§ª Testing Checklist

### Unit Tests

```javascript
const {
  extractEntities,
  extractQuotes,
  classifyKnowledgeType,
  assessImportance
} = require('../../lib/knowledge-extractor')

describe('Knowledge Extractor', () => {

  test('extractEntities finds people', () => {
    const text = 'é’æœ¨ã•ã‚“ã¯é‡ä¸­éƒæ¬¡éƒå…ˆç”Ÿã«ä¼šã„ã¾ã—ãŸã€‚'
    const entities = extractEntities(text)

    expect(entities.people).toContain('é’æœ¨ã•ã‚“')
    expect(entities.people).toContain('é‡ä¸­')
  })

  test('extractEntities finds concepts', () => {
    const text = 'é»„é‡‘ç‡ã¨ã¯ä¾¡å€¤è¦³ã®åŸºæº–ã§ã™ã€‚'
    const entities = extractEntities(text)

    expect(entities.concepts).toContain('é»„é‡‘ç‡')
    expect(entities.concepts).toContain('ä¾¡å€¤è¦³')
  })

  test('extractEntities finds ages', () => {
    const text = '29æ­³ã§ãƒã‚¤ãƒ–ãƒ«ã¨å‡ºä¼šã„ã¾ã—ãŸã€‚'
    const entities = extractEntities(text)

    expect(entities.ages).toContain(29)
  })

  test('extractQuotes finds quoted text', () => {
    const text = 'å½¼ã¯ã€Œä¿¡ç”¨ã¯å¤§åˆ‡ã§ã™ã€ã¨è¨€ã„ã¾ã—ãŸã€‚'
    const quotes = extractQuotes(text)

    expect(quotes).toContain('ä¿¡ç”¨ã¯å¤§åˆ‡ã§ã™')
  })

  test('classifyKnowledgeType identifies advice', () => {
    const text = 'äººã‚’å¤‰ãˆã‚ˆã†ã¨ã™ã‚‹ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚'
    expect(classifyKnowledgeType(text)).toBe('advice')
  })

  test('classifyKnowledgeType identifies biographical events', () => {
    const text = '29æ­³ã§ãƒã‚¤ãƒ–ãƒ«ã¨å‡ºä¼šã„ã¾ã—ãŸã€‚'
    expect(classifyKnowledgeType(text)).toBe('biographical_event')
  })

  test('assessImportance rates correctly', () => {
    const highImportance = {
      content: { quotes: ['é»„é‡‘ç‡ã¨ã¯...', 'ä¿¡ç”¨ã¯...'] },
      entities: { people: ['é’æœ¨'], concepts: ['é»„é‡‘ç‡', 'ä¿¡ç”¨'] }
    }

    expect(assessImportance(highImportance)).toBe('high')
  })
})
```

### Integration Tests

- [ ] **Test with cleaned paragraphs**:
  ```bash
  node -e "
    const pipeline = require('./lib/content-pipeline')
    // Run stages 1-3, then extract knowledge
    // Verify 30-50 knowledge objects created
  "
  ```

- [ ] **Verify extraction quality**:
  - Check that é»„é‡‘ç‡ knowledge is extracted
  - Verify quotes are preserved
  - Ensure entities are correct

### Manual Verification

- [ ] **Check key knowledge objects**:
  1. "é»„é‡‘ç‡ã¨ã®å‡ºä¼šã„" - should have:
     - Entities: é’æœ¨, ãƒã‚¤ãƒ–ãƒ«, é»„é‡‘ç‡, ãƒã‚¿ã‚¤7ç« 12ç¯€
     - Age: 29
     - Type: biographical_event
     - Importance: high
     - Quote: "ä½•äº‹ã§ã‚‚äººã€…ã‹ã‚‰..."

  2. "ä¾¡å€¤è¦³ãŒåˆã‚ãªã„äººã¨ã®è·é›¢" - should have:
     - Concepts: ä¾¡å€¤è¦³, è·é›¢, äººé–“é–¢ä¿‚
     - Type: advice
     - Importance: high
     - Quote: "ä¾¡å€¤è¦³ãŒåˆã‚ãªã„äººã¨ã¯..."

  3. "ä¿¡ç”¨ã¯ç„¡å½¢ã®è³‡æœ¬" - should have:
     - Concepts: ä¿¡ç”¨, è³‡æœ¬
     - Type: principle
     - Quote: "ä¿¡ç”¨ã¯ç„¡å½¢ã®è³‡æœ¬ãªã‚“ã§ã™"

---

## ğŸ“Š Expected Output

```javascript
{
  knowledge: [
    {
      knowledgeId: "k001",
      topic: "é»„é‡‘ç‡",
      type: "biographical_event",
      content: {
        main: "é’æœ¨ã•ã‚“ã¯29æ­³ã§ãƒã‚¤ãƒ–ãƒ«ã¨å‡ºä¼šã„...",
        context: "Full text...",
        quotes: [
          "ä½•äº‹ã§ã‚‚äººã€…ã‹ã‚‰ã—ã¦æ¬²ã—ã„ã¨æœ›ã‚€é€šã‚Šã®ã“ã¨ã‚’ä»–ã®äººã€…ã«ã‚‚ãã®ã‚ˆã†ã«ã—ãªã•ã„"
        ],
        keyTakeaway: "29æ­³ã§ã®é»„é‡‘ç‡ã¨ã®å‡ºä¼šã„ãŒäººç”Ÿã‚’å¤‰ãˆãŸ"
      },
      entities: {
        people: ["é’æœ¨"],
        concepts: ["é»„é‡‘ç‡", "ãƒã‚¤ãƒ–ãƒ«", "ãƒã‚¿ã‚¤"],
        ages: [29]
      },
      timestamp: {
        start: "00:01:19,320",
        end: "00:02:01,159"
      },
      metadata: {
        importance: "high",
        category: "life_philosophy",
        themes: ["é»„é‡‘ç‡", "ä¾¡å€¤è¦³"],
        segmentIds: [26, 27, ...]
      }
    }
    // ... more knowledge objects
  ],
  stats: {
    totalKnowledgeObjects: 35,
    highImportance: 12,
    mediumImportance: 18,
    lowImportance: 5,
    topics: 8
  }
}
```

---

## âœ¨ Success Criteria

Task is complete when:
1. âœ… Extracts 30-50 knowledge objects
2. âœ… All key topics identified correctly
3. âœ… Entities extracted accurately
4. âœ… Important quotes preserved
5. âœ… Importance levels assigned reasonably
6. âœ… All tests pass
7. âœ… Can save knowledge to JSON file

---

## ğŸ“Œ Next Task

**Task 05: Stage 5 - Semantic Chunker** (`tasks/backend/05-stage5-chunker.md`)

---

**Status**: [ ] TODO
**Started**: _____
**Completed**: _____
